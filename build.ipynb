{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from minivggnet import MiniVGGNet\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "# initialize the number of epochs to train for, base learning rate,\n",
    "# and batch size\n",
    "NUM_EPOCHS = 25\n",
    "INIT_LR = 1e-2\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Fashion MNIST...\n"
     ]
    }
   ],
   "source": [
    "# grab the Fashion MNIST dataset (if this is your first time running\n",
    "# this the dataset will be automatically downloaded)\n",
    "print(\"[INFO] loading Fashion MNIST...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the label names\n",
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray( trainX[0] , 'L')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 10\n",
    "for img_ind in range(img_num):\n",
    "    img = trainX[img_ind]\n",
    "    cv2.imshow(labelNames[trainY[img_ind]], img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 10\n",
    "for img_ind in range(img_num):\n",
    "    img = testX[img_ind]\n",
    "    cv2.imshow(labelNames[testY[img_ind]], img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-1, -1, -1],\n",
    "                       [-1, 8, -1],\n",
    "                       [-1, -1, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('signature.png')\n",
    "cv2.imshow(\"original.png\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "cv2.imshow(\"filtered.png\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.flags.writeable = True\n",
    "img_num = trainX.shape[0]\n",
    "for img_ind in range(img_num):\n",
    "    img = trainX[img_ind]\n",
    "    dst = cv2.filter2D(img,-1,kernel)\n",
    "    trainX[img_ind] = dst\n",
    "trainX.flags.writeable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.flags.writeable = True\n",
    "img_num = testX.shape[0]\n",
    "for img_ind in range(img_num):\n",
    "    img = testX[img_ind]\n",
    "    dst = cv2.filter2D(img,-1,kernel)\n",
    "    testX[img_ind] = dst\n",
    "testX.flags.writeable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 10\n",
    "for img_ind in range(img_num):\n",
    "    img = trainX[img_ind]\n",
    "    cv2.imshow(labelNames[trainY[img_ind]], img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 10\n",
    "for img_ind in range(img_num):\n",
    "    img = testX[img_ind]\n",
    "    cv2.imshow(labelNames[testY[img_ind]], img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we are using \"channels first\" ordering, then reshape the design\n",
    "# matrix such that the matrix is:\n",
    "# \tnum_samples x depth x rows x columns\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "\ttestX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    " \n",
    "# otherwise, we are using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to the range of [0, 1]\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    " \n",
    "# one-hot encode the training and testing labels\n",
    "trainY = np_utils.to_categorical(trainY, 10)\n",
    "testY = np_utils.to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.5387 - acc: 0.8212 - val_loss: 0.3117 - val_acc: 0.8864\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.3479 - acc: 0.8769 - val_loss: 0.2738 - val_acc: 0.9000\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.3019 - acc: 0.8926 - val_loss: 0.2677 - val_acc: 0.9016\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.2774 - acc: 0.9003 - val_loss: 0.2476 - val_acc: 0.9112\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.2616 - acc: 0.9077 - val_loss: 0.2417 - val_acc: 0.9116\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.2524 - acc: 0.9105 - val_loss: 0.2366 - val_acc: 0.9127\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.2413 - acc: 0.9123 - val_loss: 0.2342 - val_acc: 0.9130\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.2320 - acc: 0.9155 - val_loss: 0.2282 - val_acc: 0.9156\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.2274 - acc: 0.9174 - val_loss: 0.2269 - val_acc: 0.9166\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.2233 - acc: 0.9176 - val_loss: 0.2261 - val_acc: 0.9144\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.2190 - acc: 0.9196 - val_loss: 0.2232 - val_acc: 0.9159\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.2132 - acc: 0.9233 - val_loss: 0.2239 - val_acc: 0.9168\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.2091 - acc: 0.9240 - val_loss: 0.2263 - val_acc: 0.9165\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.2063 - acc: 0.9253 - val_loss: 0.2193 - val_acc: 0.9197\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.2031 - acc: 0.9257 - val_loss: 0.2193 - val_acc: 0.9182\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.2006 - acc: 0.9269 - val_loss: 0.2207 - val_acc: 0.9173\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.1981 - acc: 0.9270 - val_loss: 0.2225 - val_acc: 0.9181\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.1969 - acc: 0.9279 - val_loss: 0.2180 - val_acc: 0.9196\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.1938 - acc: 0.9289 - val_loss: 0.2160 - val_acc: 0.9203\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.1914 - acc: 0.9303 - val_loss: 0.2171 - val_acc: 0.9197\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.1885 - acc: 0.9306 - val_loss: 0.2161 - val_acc: 0.9208\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.1846 - acc: 0.9328 - val_loss: 0.2168 - val_acc: 0.9198\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.1838 - acc: 0.9324 - val_loss: 0.2158 - val_acc: 0.9214\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.1828 - acc: 0.9347 - val_loss: 0.2155 - val_acc: 0.9213\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.1830 - acc: 0.9335 - val_loss: 0.2148 - val_acc: 0.9207\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
    "model = MiniVGGNet.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    " \n",
    "# train the network\n",
    "print(\"[INFO] training model...\")\n",
    "H = model.fit(trainX, trainY,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tbatch_size=BS, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        top       0.86      0.89      0.87      1000\n",
      "    trouser       1.00      0.98      0.99      1000\n",
      "   pullover       0.86      0.92      0.89      1000\n",
      "      dress       0.92      0.92      0.92      1000\n",
      "       coat       0.86      0.87      0.87      1000\n",
      "     sandal       0.98      0.98      0.98      1000\n",
      "      shirt       0.80      0.73      0.77      1000\n",
      "    sneaker       0.95      0.98      0.96      1000\n",
      "        bag       0.99      0.98      0.99      1000\n",
      " ankle boot       0.98      0.96      0.97      1000\n",
      "\n",
      "avg / total       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "preds = model.predict(testX)\n",
    " \n",
    "# show a nicely formatted classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),\n",
    "\ttarget_names=labelNames))\n",
    " \n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our list of output images\n",
    "images = []\n",
    " \n",
    "# randomly select a few testing fashion items\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(16,)):\n",
    "\t# classify the clothing\n",
    "\tprobs = model.predict(testX[np.newaxis, i])\n",
    "\tprediction = probs.argmax(axis=1)\n",
    "\tlabel = labelNames[prediction[0]]\n",
    " \n",
    "\t# extract the image from the testData if using \"channels_first\"\n",
    "\t# ordering\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\timage = (testX[i][0] * 255).astype(\"uint8\")\n",
    " \n",
    "\t# otherwise we are using \"channels_last\" ordering\n",
    "\telse:\n",
    "\t\timage = (testX[i] * 255).astype(\"uint8\")\n",
    "        \n",
    "    \t# initialize the text label color as green (correct)\n",
    "\tcolor = (0, 255, 0)\n",
    " \n",
    "\t# otherwise, the class label prediction is incorrect\n",
    "\tif prediction[0] != np.argmax(testY[i]):\n",
    "\t\tcolor = (0, 0, 255)\n",
    " \n",
    "\t# merge the channels into one image and resize the image from\n",
    "\t# 28x28 to 96x96 so we can better see it and then draw the\n",
    "\t# predicted label on the image\n",
    "\timage = cv2.merge([image] * 3)\n",
    "\timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "\tcv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "\t\tcolor, 2)\n",
    " \n",
    "\t# add the image to our list of output images\n",
    "\timages.append(image)\n",
    " \n",
    "# construct the montage for the images\n",
    "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
    " \n",
    "# show the output montage\n",
    "cv2.imshow(\"Fashion MNIST\", montage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 92.07%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(testX, testY, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 92.07%\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.evaluate(testX, testY, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = load_model('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 92.07%\n"
     ]
    }
   ],
   "source": [
    "score = full_model.evaluate(testX, testY, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (full_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
